from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
from youtube_transcript_api.formatters import TextFormatter
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from xml.etree.ElementTree import ParseError
from session import ( 
    get_cached_vector_store,
    set_cached_vector_store,
    cleanup_sessions
)



from dotenv import load_dotenv

load_dotenv()

def answer_question(video_id: str, question: str, client_id: str) -> str:
    cleanup_sessions()

    vector_store = get_cached_vector_store(client_id, video_id)
    if vector_store is None:
        transcript = get_video_transcript(video_id)
        chunks = split_transcript(transcript)
        vector_store = build_vector_store(chunks)
        set_cached_vector_store(client_id, video_id, vector_store)

    retriever = get_retriever(vector_store)
    rag_chain = build_rag_chain(retriever)
    return rag_chain.invoke(question)
    
def get_video_transcript(video_id: str) -> str:
    try:
        transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
        # prefer manually created English transcript
        try:
            transcript = transcript_list.find_manually_created_transcript(['en'])

        except:
            #fallback to autogenerated english
            transcript = transcript_list.find_genrated_transcript(['en'])
        
        formatter = TextFormatter()
        return formatter.format_transcript(transcript.fetch())
    
    except (ParseError, Exception):
        raise ValueError("Transcript not accessible for this video in this environment")

def split_transcript(text: str):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size = 800,
        chunk_overlap = 100
    )
    return splitter.split_text(text)

def build_vector_store(chunks):
    embeddings = OpenAIEmbeddings(
        model = "text-embedding-3-small"
    )
    vector_store = FAISS.from_texts(chunks, embedding = embeddings)
    return vector_store

def get_retriever(vector_store):
    return vector_store.as_retriever(
        search_type = "similarity",
        search_kwargs = {"k": 4}
    )

PROMPT_TEMPLATE = """
You are a helpful assistant answering questions based only on the provided context.

Context: {context}

Question: {question}

Instructions:
- Answer clearly  and concisely
- If the answer is not in the context, say "I don't know based on this video"
"""

# Context Formatter

def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# chain Builder

def build_rag_chain(retriever):
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.2
    )

    prompt = PromptTemplate(
        template=PROMPT_TEMPLATE,
        input_variables=["context", "question"]
    )

    chain = (
        RunnableParallel(
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough(),
            }
        )
        | prompt
        | llm
        | StrOutputParser()
    )

    return chain
def build_rag_chain(retriever):
    llm = ChatOpenAI(
        model="gpt-3.5-turbo",
        temperature=0.2
    )

    prompt = PromptTemplate(
        template=PROMPT_TEMPLATE,
        input_variables=["context", "question"]
    )

    chain = (
        RunnableParallel(
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough(),
            }
        )
        | prompt
        | llm
        | StrOutputParser()
    )

    return chain



